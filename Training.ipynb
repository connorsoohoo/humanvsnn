{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce 940MX\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from net import *\n",
    "\n",
    "# see if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "\n",
    "# reduce dataset sizes for debugging model\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "transform = transforms.Compose([\n",
    "    # Must convert all images to tensors first to be processed.\n",
    "    transforms.ToTensor(),\n",
    "    # Normalize images to mean 0, variance 1 (improves training)\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# load the train set\n",
    "train_set = CIFAR10(\"data\", train=True, transform=transform, download=True)\n",
    "n_train = len(train_set)\n",
    "\n",
    "if DEBUG:\n",
    "    n_train = 128\n",
    "    train_set = [train_set[i] for i in range(n_train)]\n",
    "\n",
    "# Create a loader for the training set\n",
    "train_loader = DataLoader(train_set,batch_size=batch_size,shuffle=True,num_workers=4)\n",
    "\n",
    "# Load the test set, note that train is set to False\n",
    "test_set = CIFAR10(root=\"data\", train=False, transform=transform, download=True)\n",
    "n_test = len(test_set)\n",
    "\n",
    "if DEBUG:\n",
    "    n_test = 128\n",
    "    test_set = [test_set[i] for i in range(n_test)]\n",
    "\n",
    "# Create a loder for the test set, note that both shuffle is set to false for the test loader\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size,shuffle=False, num_workers=4)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saves a model \n",
    "def save_models(model, model_name, epoch):\n",
    "    \n",
    "    directory = \"models/{0}/\".format(model_name)\n",
    "    filename = \"{0}.pth\".format(epoch)\n",
    "    \n",
    "    # make the directory if it doesn't already exist\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    torch.save(model.state_dict(), directory + filename)\n",
    "    print(\"Checkpoint saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate performance of a model\n",
    "def test(model):\n",
    "    model.eval()\n",
    "    test_acc = 0.0\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "    \n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "\n",
    "        # Predict classes using images from the test set\n",
    "        outputs = model(images)\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        \n",
    "        test_acc += int(torch.sum(prediction == labels.data))\n",
    "\n",
    "    # Compute the average acc and loss over all 10000 test images\n",
    "    test_acc = test_acc / n_test\n",
    "\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trains a model and saves it if it has the best test accuracy we've seen so far\n",
    "def train(model, optimizer, loss_fn, num_epochs, cuda_avail=False, save_model=False, model_name=\"\", verbose=False):\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    # if cuda is available, move the model to the GPU\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        train_acc = 0.0\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            \n",
    "            # Move images and labels to gpu if available\n",
    "            if cuda_avail:\n",
    "                images = Variable(images.cuda())\n",
    "                labels = Variable(labels.cuda())\n",
    "\n",
    "            # Clear all accumulated gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Predict classes using images from the test set\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Compute the loss based on the predictions and actual labels\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            # Backpropagate the loss\n",
    "            loss.backward()\n",
    "\n",
    "            # Adjust parameters according to the computed gradients\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.cpu().data.item() * images.size(0)\n",
    "            _, prediction = torch.max(outputs.data, 1)\n",
    "            \n",
    "            train_acc += int(torch.sum(prediction == labels.data))\n",
    "\n",
    "        # Compute the average acc and loss over all training images\n",
    "        train_acc = train_acc / n_train\n",
    "        train_loss = train_loss / n_train\n",
    "\n",
    "        # Evaluate on the test set\n",
    "        test_acc = test(model, cuda_avail)\n",
    "\n",
    "        # Save the model (saving criteria should not be test acc, as this is cheating)\n",
    "        if save_model:\n",
    "            save_models(model, model_name, epoch)\n",
    "            \n",
    "        end = time.time()\n",
    "        ep_time = end - start\n",
    "\n",
    "        # Print the metrics\n",
    "        if verbose:\n",
    "            print(\"Epoch {0}, Train Accuracy: {1:.3f} , TrainLoss: {2:.3f} , Test Accuracy: {3:.3f}, Time: {4:.2f}s\".format(epoch, train_acc, train_loss, test_acc, ep_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SimpleNet_conv=2_ch=32\n",
      "Checkpoint saved\n",
      "Epoch 0, Train Accuracy: 0.545 , TrainLoss: 1.272 , Test Accuracy: 0.662, Time: 646.40s\n",
      "Checkpoint saved\n",
      "Epoch 1, Train Accuracy: 0.687 , TrainLoss: 0.888 , Test Accuracy: 0.704, Time: 74.83s\n",
      "Checkpoint saved\n",
      "Epoch 2, Train Accuracy: 0.733 , TrainLoss: 0.761 , Test Accuracy: 0.744, Time: 94.08s\n",
      "Checkpoint saved\n",
      "Epoch 3, Train Accuracy: 0.758 , TrainLoss: 0.690 , Test Accuracy: 0.758, Time: 81.54s\n",
      "Checkpoint saved\n",
      "Epoch 4, Train Accuracy: 0.779 , TrainLoss: 0.634 , Test Accuracy: 0.755, Time: 80.63s\n",
      "Checkpoint saved\n",
      "Epoch 5, Train Accuracy: 0.795 , TrainLoss: 0.585 , Test Accuracy: 0.775, Time: 90.77s\n",
      "Checkpoint saved\n",
      "Epoch 6, Train Accuracy: 0.808 , TrainLoss: 0.552 , Test Accuracy: 0.774, Time: 85.05s\n",
      "Checkpoint saved\n",
      "Epoch 7, Train Accuracy: 0.820 , TrainLoss: 0.516 , Test Accuracy: 0.768, Time: 80.17s\n",
      "Checkpoint saved\n",
      "Epoch 8, Train Accuracy: 0.827 , TrainLoss: 0.491 , Test Accuracy: 0.769, Time: 72.40s\n",
      "Checkpoint saved\n",
      "Epoch 9, Train Accuracy: 0.838 , TrainLoss: 0.464 , Test Accuracy: 0.774, Time: 72.17s\n",
      "Checkpoint saved\n",
      "Epoch 10, Train Accuracy: 0.845 , TrainLoss: 0.444 , Test Accuracy: 0.771, Time: 72.11s\n",
      "Checkpoint saved\n",
      "Epoch 11, Train Accuracy: 0.849 , TrainLoss: 0.427 , Test Accuracy: 0.779, Time: 70.20s\n",
      "Checkpoint saved\n",
      "Epoch 12, Train Accuracy: 0.857 , TrainLoss: 0.404 , Test Accuracy: 0.782, Time: 70.36s\n",
      "Checkpoint saved\n",
      "Epoch 13, Train Accuracy: 0.864 , TrainLoss: 0.385 , Test Accuracy: 0.782, Time: 71.01s\n",
      "Checkpoint saved\n",
      "Epoch 14, Train Accuracy: 0.869 , TrainLoss: 0.371 , Test Accuracy: 0.780, Time: 72.47s\n",
      "Checkpoint saved\n",
      "Epoch 15, Train Accuracy: 0.874 , TrainLoss: 0.355 , Test Accuracy: 0.777, Time: 76.26s\n",
      "Checkpoint saved\n",
      "Epoch 16, Train Accuracy: 0.877 , TrainLoss: 0.346 , Test Accuracy: 0.778, Time: 77.71s\n",
      "Checkpoint saved\n",
      "Epoch 17, Train Accuracy: 0.882 , TrainLoss: 0.331 , Test Accuracy: 0.777, Time: 74.39s\n",
      "Checkpoint saved\n",
      "Epoch 18, Train Accuracy: 0.887 , TrainLoss: 0.318 , Test Accuracy: 0.781, Time: 81.62s\n",
      "Checkpoint saved\n",
      "Epoch 19, Train Accuracy: 0.890 , TrainLoss: 0.309 , Test Accuracy: 0.780, Time: 75.03s\n",
      "Checkpoint saved\n",
      "Epoch 20, Train Accuracy: 0.895 , TrainLoss: 0.298 , Test Accuracy: 0.780, Time: 71.09s\n",
      "Checkpoint saved\n",
      "Epoch 21, Train Accuracy: 0.898 , TrainLoss: 0.285 , Test Accuracy: 0.776, Time: 72.77s\n",
      "Checkpoint saved\n",
      "Epoch 22, Train Accuracy: 0.900 , TrainLoss: 0.280 , Test Accuracy: 0.774, Time: 70.91s\n",
      "Checkpoint saved\n",
      "Epoch 23, Train Accuracy: 0.904 , TrainLoss: 0.269 , Test Accuracy: 0.768, Time: 70.75s\n",
      "Checkpoint saved\n",
      "Epoch 24, Train Accuracy: 0.905 , TrainLoss: 0.262 , Test Accuracy: 0.773, Time: 70.57s\n",
      "Checkpoint saved\n",
      "Epoch 25, Train Accuracy: 0.906 , TrainLoss: 0.259 , Test Accuracy: 0.773, Time: 70.77s\n",
      "Checkpoint saved\n",
      "Epoch 26, Train Accuracy: 0.913 , TrainLoss: 0.244 , Test Accuracy: 0.776, Time: 71.10s\n",
      "Checkpoint saved\n",
      "Epoch 27, Train Accuracy: 0.912 , TrainLoss: 0.241 , Test Accuracy: 0.776, Time: 71.12s\n",
      "Checkpoint saved\n",
      "Epoch 28, Train Accuracy: 0.916 , TrainLoss: 0.235 , Test Accuracy: 0.777, Time: 73.82s\n",
      "Checkpoint saved\n",
      "Epoch 29, Train Accuracy: 0.916 , TrainLoss: 0.230 , Test Accuracy: 0.773, Time: 70.58s\n",
      "Checkpoint saved\n",
      "Epoch 30, Train Accuracy: 0.920 , TrainLoss: 0.222 , Test Accuracy: 0.774, Time: 70.53s\n",
      "Checkpoint saved\n",
      "Epoch 31, Train Accuracy: 0.920 , TrainLoss: 0.222 , Test Accuracy: 0.770, Time: 72.66s\n",
      "Checkpoint saved\n",
      "Epoch 32, Train Accuracy: 0.924 , TrainLoss: 0.209 , Test Accuracy: 0.771, Time: 72.10s\n",
      "Checkpoint saved\n",
      "Epoch 33, Train Accuracy: 0.926 , TrainLoss: 0.205 , Test Accuracy: 0.774, Time: 70.26s\n",
      "Checkpoint saved\n",
      "Epoch 34, Train Accuracy: 0.926 , TrainLoss: 0.202 , Test Accuracy: 0.777, Time: 69.43s\n",
      "Checkpoint saved\n",
      "Epoch 35, Train Accuracy: 0.930 , TrainLoss: 0.194 , Test Accuracy: 0.769, Time: 69.71s\n",
      "Checkpoint saved\n",
      "Epoch 36, Train Accuracy: 0.930 , TrainLoss: 0.193 , Test Accuracy: 0.776, Time: 71.14s\n",
      "Checkpoint saved\n",
      "Epoch 37, Train Accuracy: 0.932 , TrainLoss: 0.185 , Test Accuracy: 0.771, Time: 70.42s\n",
      "Checkpoint saved\n",
      "Epoch 38, Train Accuracy: 0.933 , TrainLoss: 0.183 , Test Accuracy: 0.768, Time: 70.36s\n",
      "Checkpoint saved\n",
      "Epoch 39, Train Accuracy: 0.936 , TrainLoss: 0.177 , Test Accuracy: 0.771, Time: 70.18s\n",
      "Checkpoint saved\n",
      "Epoch 40, Train Accuracy: 0.937 , TrainLoss: 0.174 , Test Accuracy: 0.775, Time: 73.46s\n",
      "Checkpoint saved\n",
      "Epoch 41, Train Accuracy: 0.938 , TrainLoss: 0.169 , Test Accuracy: 0.773, Time: 80.20s\n",
      "Checkpoint saved\n",
      "Epoch 42, Train Accuracy: 0.938 , TrainLoss: 0.170 , Test Accuracy: 0.773, Time: 71.46s\n",
      "Checkpoint saved\n",
      "Epoch 43, Train Accuracy: 0.941 , TrainLoss: 0.161 , Test Accuracy: 0.776, Time: 73.00s\n",
      "Checkpoint saved\n",
      "Epoch 44, Train Accuracy: 0.940 , TrainLoss: 0.165 , Test Accuracy: 0.772, Time: 70.10s\n",
      "Checkpoint saved\n",
      "Epoch 45, Train Accuracy: 0.942 , TrainLoss: 0.158 , Test Accuracy: 0.774, Time: 71.87s\n",
      "Checkpoint saved\n",
      "Epoch 46, Train Accuracy: 0.945 , TrainLoss: 0.152 , Test Accuracy: 0.775, Time: 73.64s\n",
      "Checkpoint saved\n",
      "Epoch 47, Train Accuracy: 0.943 , TrainLoss: 0.157 , Test Accuracy: 0.775, Time: 77.78s\n",
      "Checkpoint saved\n",
      "Epoch 48, Train Accuracy: 0.946 , TrainLoss: 0.151 , Test Accuracy: 0.769, Time: 74.06s\n",
      "Checkpoint saved\n",
      "Epoch 49, Train Accuracy: 0.947 , TrainLoss: 0.144 , Test Accuracy: 0.776, Time: 75.31s\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "save_model = True\n",
    "\n",
    "for num_conv in [2]:\n",
    "    for num_channels in [32]:\n",
    "        \n",
    "        model_name = \"SimpleNet_conv=%d_ch=%d\" % (num_conv, num_channels)\n",
    "        print(\"Training\", model_name)\n",
    "        \n",
    "        # Create model, optimizer and loss function\n",
    "        models[model_name] = SimpleNet(num_conv=num_conv, num_channels=num_channels, num_classes=10)\n",
    "\n",
    "        # Define the optimizer and loss function\n",
    "        optimizer = Adam(models[model_name].parameters(), lr=0.001)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Train loop\n",
    "        train(models[model_name], optimizer, loss_fn, num_epochs, \n",
    "              save_model=save_model, model_name=model_name, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
